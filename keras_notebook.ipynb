{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Chest X-Ray Medical Diagnosis with Deep Learning\n",
    "\n",
    "<img src=\"images/xray-header-image.png\" style=\"padding-top: 50px;width: 500px; height:500px; left: 0px;margin-left: 0px;margin-right: 0px;\">\n",
    "\n",
    "In this assignment you will explore medical image diagnosis by building a state-of-the-art chest X-ray classifier using Keras.\n",
    "\n",
    "The assignment will walk through some of the steps of building and evaluating this deep learning classifier model. In particular, you will:\n",
    "- Pre-process and prepare a real-world X-ray dataset.\n",
    "- Use transfer learning to retrain a DenseNet model for X-ray image classification.\n",
    "- Learn a technique to handle class imbalance\n",
    "- Measure diagnostic performance by computing the AUC (Area Under the Curve) for the ROC (Receiver Operating Characteristic) curve.\n",
    "- Visualize model activity using GradCAMs.\n",
    "\n",
    "In completing this assignment you will learn about the following topics:\n",
    "\n",
    "- Data preparation\n",
    "  - Visualizing data.\n",
    "  - Preventing data leakage.\n",
    "- Model Development\n",
    "  - Addressing class imbalance.\n",
    "  - Leveraging pre-trained models using transfer learning.\n",
    "- Evaluation\n",
    "  - AUC and ROC curves."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Table of Contents\n",
    "\n",
    "- [1. Import Packages and Functions](#1)\n",
    "- [2. Load the Datasets](#2)\n",
    "    - [2.1 Loading the Data](#2-1)\n",
    "    - [2.2 Preventing Data Leakage](#2-2)\n",
    "        - [Exercise 1 - check for Leakage](#Ex-1)\n",
    "    - [2.3 Preparing Images](#2-3)\n",
    "- [3. Model Development](#3)\n",
    "    - [3.1 Addressing Class Imbalance](#3-1)\n",
    "        - [Exercise 2 - compute Class Frequencies](#Ex-2)\n",
    "        - [Exercise 3 - get Weighted Loss](#Ex-3)\n",
    "    - [3.2 DenseNet121](#3-2)\n",
    "- [4. Training (Optional)](#4)\n",
    "    - [4.1 Training on the Larger Dataset](#4-1)\n",
    "- [5. Prediction and Evaluation](#5)\n",
    "    - [5.1 ROC Curve and AUROC](#5-1)\n",
    "    - [5.2 Visualizing Learning with GradCAM](#5-2)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name='1'></a>\n",
    "## 1. Import Packages and Functions\n",
    "\n",
    "We'll make use of the following packages:\n",
    "- `numpy` and `pandas` is what we'll use to manipulate our data\n",
    "- `matplotlib.pyplot` and `seaborn` will be used to produce plots for visualization\n",
    "- `util` will provide the locally defined utility functions that have been provided for this assignment\n",
    "\n",
    "We will also use several modules from the `keras` framework for building deep learning models.\n",
    "\n",
    "Run the next cell to import all the necessary packages."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.applications.densenet import DenseNet121\n",
    "from keras.layers import Dense, GlobalAveragePooling2D\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import load_model\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from public_tests import *\n",
    "from test_utils import *"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name='2'></a>\n",
    "## 2. Load the Datasets\n",
    "\n",
    "For this assignment, we will be using the [ChestX-ray8 dataset](https://arxiv.org/abs/1705.02315) which contains 108,948 frontal-view X-ray images of 32,717 unique patients.\n",
    "- Each image in the data set contains multiple text-mined labels identifying 14 different pathological conditions.\n",
    "- These in turn can be used by physicians to diagnose 8 different diseases.\n",
    "- We will use this data to develop a single model that will provide binary classification predictions for each of the 14 labeled pathologies.\n",
    "- In other words it will predict 'positive' or 'negative' for each of the pathologies.\n",
    "\n",
    "You can download the entire dataset for free [here](https://nihcc.app.box.com/v/ChestXray-NIHCC).\n",
    "- We have provided a ~1000 image subset of the images for you.\n",
    "- These can be accessed in the folder path stored in the `IMAGE_DIR` variable.\n",
    "\n",
    "The dataset includes a CSV file that provides the labels for each X-ray.\n",
    "\n",
    "To make your job a bit easier, we have processed the labels for our small sample and generated three new files to get you started. These three files are:\n",
    "\n",
    "1. `nih/train-small.csv`: 875 images from our dataset to be used for training.\n",
    "1. `nih/valid-small.csv`: 109 images from our dataset to be used for validation.\n",
    "1. `nih/test.csv`: 420 images from our dataset to be used for testing.\n",
    "\n",
    "This dataset has been annotated by consensus among four different radiologists for 5 of our 14 pathologies:\n",
    "- `Consolidation`\n",
    "- `Edema`\n",
    "- `Effusion`\n",
    "- `Cardiomegaly`\n",
    "- `Atelectasis`"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name='2-1'></a>\n",
    "### 2.1 Loading the Data\n",
    "Let's open these files using the [pandas](https://pandas.pydata.org/) library"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "              Image  Atelectasis  Cardiomegaly  Consolidation  Edema  \\\n0  00008270_015.png            0             0              0      0   \n1  00029855_001.png            1             0              0      0   \n2  00001297_000.png            0             0              0      0   \n3  00012359_002.png            0             0              0      0   \n4  00017951_001.png            0             0              0      0   \n\n   Effusion  Emphysema  Fibrosis  Hernia  Infiltration  Mass  Nodule  \\\n0         0          0         0       0             0     0       0   \n1         1          0         0       0             1     0       0   \n2         0          0         0       0             0     0       0   \n3         0          0         0       0             0     0       0   \n4         0          0         0       0             1     0       0   \n\n   PatientId  Pleural_Thickening  Pneumonia  Pneumothorax  \n0       8270                   0          0             0  \n1      29855                   0          0             0  \n2       1297                   1          0             0  \n3      12359                   0          0             0  \n4      17951                   0          0             0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Image</th>\n      <th>Atelectasis</th>\n      <th>Cardiomegaly</th>\n      <th>Consolidation</th>\n      <th>Edema</th>\n      <th>Effusion</th>\n      <th>Emphysema</th>\n      <th>Fibrosis</th>\n      <th>Hernia</th>\n      <th>Infiltration</th>\n      <th>Mass</th>\n      <th>Nodule</th>\n      <th>PatientId</th>\n      <th>Pleural_Thickening</th>\n      <th>Pneumonia</th>\n      <th>Pneumothorax</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00008270_015.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>8270</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00029855_001.png</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>29855</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>00001297_000.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1297</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>00012359_002.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>12359</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>00017951_001.png</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>17951</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"data/train-small.csv\")\n",
    "valid_df = pd.read_csv(\"data/valid-small.csv\")\n",
    "\n",
    "test_df = pd.read_csv(\"data/test.csv\")\n",
    "\n",
    "train_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [],
   "source": [
    "labels = ['Cardiomegaly',\n",
    "          'Emphysema',\n",
    "          'Effusion',\n",
    "          'Hernia',\n",
    "          'Infiltration',\n",
    "          'Mass',\n",
    "          'Nodule',\n",
    "          'Atelectasis',\n",
    "          'Pneumothorax',\n",
    "          'Pleural_Thickening',\n",
    "          'Pneumonia',\n",
    "          'Fibrosis',\n",
    "          'Edema',\n",
    "          'Consolidation']"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name='2-2'></a>\n",
    "### 2.2 Preventing Data Leakage\n",
    "It is worth noting that our dataset contains multiple images for each patient. This could be the case, for example, when a patient has taken multiple X-ray images at different times during their hospital visits. In our data splitting, we have ensured that the split is done on the patient level so that there is no data \"leakage\" between the train, validation, and test datasets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a name='Ex-1'></a>\n",
    "### Exercise 1 - Check for Leakage\n",
    "In the cell below, write a function to check whether there is leakage between two datasets. We'll use this to make sure there are no patients in the test set that are also present in either the train or validation sets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_for_leakage_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [9]\u001B[0m, in \u001B[0;36m<cell line: 30>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     27\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m leakage\n\u001B[0;32m     29\u001B[0m \u001B[38;5;66;03m### do not edit this code cell\u001B[39;00m\n\u001B[1;32m---> 30\u001B[0m \u001B[43mcheck_for_leakage_test\u001B[49m(check_for_leakage)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'check_for_leakage_test' is not defined"
     ]
    }
   ],
   "source": [
    "# UNQ_C1 (UNIQUE CELL IDENTIFIER, DO NOT EDIT)\n",
    "def check_for_leakage(df1, df2, patient_col):\n",
    "    \"\"\"\n",
    "    Return True if there any patients are in both df1 and df2.\n",
    "\n",
    "    Args:\n",
    "        df1 (dataframe): dataframe describing first dataset\n",
    "        df2 (dataframe): dataframe describing second dataset\n",
    "        patient_col (str): string name of column with patient IDs\n",
    "\n",
    "    Returns:\n",
    "        leakage (bool): True if there is leakage, otherwise False\n",
    "    \"\"\"\n",
    "\n",
    "    ### START CODE HERE (REPLACE INSTANCES OF 'None' with your code) ###\n",
    "\n",
    "    df1_patients_unique = df1[patient_col].unique().tolist()\n",
    "    df2_patients_unique = df2[patient_col].unique().tolist()\n",
    "\n",
    "    patients_in_both_groups = set(df1_patients_unique).intersection(set(df2_patients_unique))\n",
    "\n",
    "    # leakage contains true if there is patient overlap, otherwise false.\n",
    "    leakage = True if len(patients_in_both_groups) else False # boolean (true if there is at least 1 patient in both groups)\n",
    "\n",
    "    ### END CODE HERE ###\n",
    "\n",
    "    return leakage\n",
    "\n",
    "### do not edit this code cell\n",
    "check_for_leakage_test(check_for_leakage)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_for_leakage_test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Input \u001B[1;32mIn [8]\u001B[0m, in \u001B[0;36m<cell line: 2>\u001B[1;34m()\u001B[0m\n\u001B[0;32m      1\u001B[0m \u001B[38;5;66;03m### do not edit this code cell\u001B[39;00m\n\u001B[1;32m----> 2\u001B[0m \u001B[43mcheck_for_leakage_test\u001B[49m(check_for_leakage)\n",
      "\u001B[1;31mNameError\u001B[0m: name 'check_for_leakage_test' is not defined"
     ]
    }
   ],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}